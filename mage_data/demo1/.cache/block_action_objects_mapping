{"block_file": {"charts/completed_pipeline_runs_daily_cold_music_g1.py:chart:python:completed pipeline runs daily cold music g1": {"content": "\n@data_source\ndef d(df):\n    return df[df['status'] == 'completed']\n", "file_path": "charts/completed_pipeline_runs_daily_cold_music_g1.py", "language": "python", "type": "chart", "uuid": "completed_pipeline_runs_daily_cold_music_g1"}, "charts/completed_pipeline_runs_daily_pizza_sales_etl_t5.py:chart:python:completed pipeline runs daily pizza sales etl t5": {"content": "\n@data_source\ndef d(df):\n    return df[df['status'] == 'completed']\n", "file_path": "charts/completed_pipeline_runs_daily_pizza_sales_etl_t5.py", "language": "python", "type": "chart", "uuid": "completed_pipeline_runs_daily_pizza_sales_etl_t5"}, "charts/data_loader_bar_chart_a5.py:chart:python:data loader bar chart a5": {"content": "columns = df_1.columns\nx = df_1.columns[:7]\ny = [[v] for v in [len(df_1[col].unique()) for col in x]]\n", "file_path": "charts/data_loader_bar_chart_a5.py", "language": "python", "type": "chart", "uuid": "data_loader_bar_chart_a5"}, "charts/difcol_bar_chart_d3.py:chart:python:difcol bar chart d3": {"content": "columns = df_1.columns\nx = df_1.columns[:7]\ny = [[v] for v in [len(df_1[col].unique()) for col in x]]\n", "file_path": "charts/difcol_bar_chart_d3.py", "language": "python", "type": "chart", "uuid": "difcol_bar_chart_d3"}, "charts/distribution1_line_chart_w4.py:chart:python:distribution1 line chart w4": {"content": "columns = df_1.columns\ncols = list(filter(lambda x: df_1[x].dtype == float or df_1[x].dtype == int, columns))\nx = df_1[cols[0]]\ny = [df_1[cols[1]]]\n", "file_path": "charts/distribution1_line_chart_w4.py", "language": "python", "type": "chart", "uuid": "distribution1_line_chart_w4"}, "charts/duplicate_sales_line_chart_i9.py:chart:python:duplicate sales line chart i9": {"content": "columns = df_1.columns\ncols = list(filter(lambda x: df_1[x].dtype == float or df_1[x].dtype == int, columns))\nx = df_1[cols[0]]\ny = [df_1[cols[1]]]\n", "file_path": "charts/duplicate_sales_line_chart_i9.py", "language": "python", "type": "chart", "uuid": "duplicate_sales_line_chart_i9"}, "charts/duplicate_sales_line_chart_o8.py:chart:python:duplicate sales line chart o8": {"content": "columns = df_1.columns\ncols = list(filter(lambda x: df_1[x].dtype == float or df_1[x].dtype == int, columns))\nx = df_1[cols[0]]\ny = [df_1[cols[1]]]\n", "file_path": "charts/duplicate_sales_line_chart_o8.py", "language": "python", "type": "chart", "uuid": "duplicate_sales_line_chart_o8"}, "charts/failed_pipeline_runs_daily_cold_music_c8.py:chart:python:failed pipeline runs daily cold music c8": {"content": "\n@data_source\ndef d(df):\n    return df[df['status'] == 'failed']\n", "file_path": "charts/failed_pipeline_runs_daily_cold_music_c8.py", "language": "python", "type": "chart", "uuid": "failed_pipeline_runs_daily_cold_music_c8"}, "charts/failed_pipeline_runs_daily_pizza_sales_etl_z1.py:chart:python:failed pipeline runs daily pizza sales etl z1": {"content": "\n@data_source\ndef d(df):\n    return df[df['status'] == 'failed']\n", "file_path": "charts/failed_pipeline_runs_daily_pizza_sales_etl_z1.py", "language": "python", "type": "chart", "uuid": "failed_pipeline_runs_daily_pizza_sales_etl_z1"}, "charts/prizza_data_loader_bar_chart_u6.py:chart:python:prizza data loader bar chart u6": {"content": "columns = df_1.columns\nx = df_1.columns[:7]\ny = [[v] for v in [len(df_1[col].unique()) for col in x]]\n", "file_path": "charts/prizza_data_loader_bar_chart_u6.py", "language": "python", "type": "chart", "uuid": "prizza_data_loader_bar_chart_u6"}, "charts/prizza_data_loader_pie_chart_v9.py:chart:python:prizza data loader pie chart v9": {"content": "x = df_1[df_1.columns[0]]", "file_path": "charts/prizza_data_loader_pie_chart_v9.py", "language": "python", "type": "chart", "uuid": "prizza_data_loader_pie_chart_v9"}, "charts/product_filter_transform_histogram_n0.py:chart:python:product filter transform histogram n0": {"content": "columns = df_1.columns\ncol = list(filter(lambda x: df_1[x].dtype == float or df_1[x].dtype == int, columns))[0]\nx = df_1[col]\n", "file_path": "charts/product_filter_transform_histogram_n0.py", "language": "python", "type": "chart", "uuid": "product_filter_transform_histogram_n0"}, "charts/split_data_line_chart_g1.py:chart:python:split data line chart g1": {"content": "columns = df_1.columns\ncols = list(filter(lambda x: df_1[x].dtype == float or df_1[x].dtype == int, columns))\nx = df_1[cols[0]]\ny = [df_1[cols[1]]]\n", "file_path": "charts/split_data_line_chart_g1.py", "language": "python", "type": "chart", "uuid": "split_data_line_chart_g1"}, "custom/check_datatypes.py:custom:python:check datatypes": {"content": "import pandas as pd\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame,*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n\n    print(\"Data types:\")\n    print(df.dtypes)\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/check_datatypes.py", "language": "python", "type": "custom", "uuid": "check_datatypes"}, "custom/covert_to_date.py:custom:python:covert to date": {"content": "import pandas as pd  # Import pandas for data manipulation\nfrom dateutil import parser\nimport numpy as np\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame ,*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n\n    df['order_date'] = pd.to_datetime(df['order_date'],format='%d/%m/%Y', errors='coerce')\n\n    print(\"Data types:\")\n    print(df.dtypes)\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/covert_to_date.py", "language": "python", "type": "custom", "uuid": "covert_to_date"}, "custom/crete_features.py:custom:python:crete features": {"content": "if 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df, *args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n    # Extract year, day of the week, quarter, month, day of the year, day of the month,\n    # and week of the year from the 'order_date' column \n    df['year'] = df['order_date'].dt.year\n    df['month'] = df['order_date'].dt.month\n    df['quarter'] = df['order_date'].dt.quarter\n    df['dayofweek'] = df['order_date'].dt.dayofweek\n    df['dayofyear'] = df['order_date'].dt.dayofyear\n    df['dayofmonth'] = df['order_date'].dt.day\n    df['weekofyear'] = df['order_date'].dt.isocalendar().week\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/crete_features.py", "language": "python", "type": "custom", "uuid": "crete_features"}, "custom/custom_changedatatypes.py:custom:python:custom changedatatypes": {"content": "import pandas as pd\nfrom datetime import datetime\nfrom dateutil import parser\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame,*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n\n\n    try:\n        # Convert 'order_date' column to datetime with specified format\n        df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')\n    except Exception as e:\n        # If an error occurs during conversion, handle it gracefully\n        print(f\"Error occurred during conversion: {e}\")\n\n\n    # Return the modified DataFrame\n    return df\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n    assert isinstance(output, pd.DataFrame), 'Output should be a DataFrame'\n\n    # Check if 'order_date' column has been converted to datetime\n    assert output['order_date'].dtype == 'datetime64[ns]', \"The 'order_date' column should be of type datetime\"\n", "file_path": "custom/custom_changedatatypes.py", "language": "python", "type": "custom", "uuid": "custom_changedatatypes"}, "custom/custom_check_datatypes.py:custom:python:custom check datatypes": {"content": "import pandas as pd\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame, *args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n\n    print(\"Data types:\")\n    print(df.dtypes)\n\n    return df\n    # Initialize an empty dictionary to store column names and their data types\n    # data_types = {}\n\n    # # Iterate through each column in the DataFrame\n    # for column in df.columns:\n    #     # Get the data type of the column and store it in the dictionary\n    #     data_types[column] = str(df[column].dtype)\n\n    # # Return the dictionary containing column names and their data types\n    # return data_types\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/custom_check_datatypes.py", "language": "python", "type": "custom", "uuid": "custom_check_datatypes"}, "custom/datetime_covert.py:custom:python:datetime covert": {"content": "import pandas as pd  # Import pandas for data manipulation\nfrom dateutil import parser\nimport numpy as np\n\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame,*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n\n    \"\"\"\n\n    df['order_date'] = pd.to_datetime(df['order_date'],format='%m/%d/%Y', errors='coerce')\n\n    print(\"Data types:\")\n    print(df.dtypes)\n\n    return df\n\n\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/datetime_covert.py", "language": "python", "type": "custom", "uuid": "datetime_covert"}, "custom/define_encoding.py:custom:python:define encoding": {"content": "import pandas as pd  # Import pandas for data manipulation\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df,*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n    \n    # Define the encoding mappings\n    brand_encoding_mapping = {'A. Datum': 0, 'Adventure Works': 1, 'Adventure Works ': 2, 'Contoso': 3, 'Fabrikam': 4, 'Fabrikam  ': 5, 'Litware': 6, 'Litware ': 7, 'Northwind Traders': 8, 'Proseware': 9, 'Southridge Video': 10, 'The Phone Company': 11, 'Wide World Importers': 12}\n    category_encoding_mapping = {'Audio': 0, 'Cameras and camcorders ': 1, 'Cell phones': 2, 'Computers': 3, 'Music, Movies and Audio Books': 4, 'TV and Video': 5}\n    channel_encoding_mapping = {'Mobile Outlet': 0, 'Online': 1, 'Reseller': 2, 'Store': 3}\n\n\n\n    # Apply encoding to DataFrame\n    df['BrandNameEn'] = df['brand_name'].map(brand_encoding_mapping)\n    df['CategoryNameEn'] = df['product_category'].map(category_encoding_mapping)\n    df['ChannelNameEn'] = df['channel_name'].map(channel_encoding_mapping)\n\n    # Drop original columns \n    df.drop(columns=['brand_name', 'product_category', 'channel_name'], inplace=True)\n    \n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/define_encoding.py", "language": "python", "type": "custom", "uuid": "define_encoding"}, "custom/nullhandline_ml.py:custom:python:nullhandline ml": {"content": "import pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.impute import SimpleImputer\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, *args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n\n\n\n    # Load the previously trained XGBoost model\n    model = joblib.load('xgboost_model_sales.pkl')\n\n    # Define your features\n    FEATURES = ['year', 'month', 'quarter', 'dayofweek', 'dayofyear', 'dayofmonth', 'weekofyear','order_qty','price','CategoryNameEn','BrandNameEn','ChannelNameEn']\n    TARGET = 'sales'\n\n    # Check for null values in the 'sales' column\n    null_sales_indices = data[data['sales'].isnull()].index\n\n    # Fill null values in 'sales' column using the trained model\n    for index in null_sales_indices:\n        # Extract features for prediction\n        features = data.loc[index, FEATURES].values.reshape(1, -1)\n        \n        # Predict sales value\n        predicted_sales = model.predict(features)\n        \n        # Fill null value with predicted sales\n        data.at[index, 'sales'] = predicted_sales[0]\n\n    # Save the updated dataset\n    data.to_csv('filled_dataset.csv', index=False)  # Save the dataset to a new CSV file\n\n    print(data.isnull().sum())\n    print(data.info())\n\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/nullhandline_ml.py", "language": "python", "type": "custom", "uuid": "nullhandline_ml"}, "custom/null_check.py:custom:python:null check": {"content": "import pandas as pd  # Import pandas for data manipulation\nimport numpy as np\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame , *args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n    print(df.isnull().sum())\n    print(df.info())\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/null_check.py", "language": "python", "type": "custom", "uuid": "null_check"}, "custom/null_count.py:custom:python:null count": {"content": "import pandas as pd\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(df: pd.DataFrame,*args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your custom logic here\n    # Count null values in each row\n    # Count null values row-wise\n    null_counts = df.isnull().sum(axis=1)\n\n    # Return the null value counts per row\n    return null_counts\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "custom/null_count.py", "language": "python", "type": "custom", "uuid": "null_count"}, "data_exporters/export_salesdata.py:data_exporter:python:export salesdata": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/ML/Sales_test_data_new1.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/export_salesdata.py", "language": "python", "type": "data_exporter", "uuid": "export_salesdata"}, "data_exporters/export_titanic_clean.py:data_exporter:python:export titanic clean": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#example-loading-data-from-a-file\n    \"\"\"\n    filepath = 'titanic_clean.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/export_titanic_clean.py", "language": "python", "type": "data_exporter", "uuid": "export_titanic_clean"}, "data_exporters/export_to_csv.py:data_exporter:python:export to csv": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './pizza_sales_edited.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/export_to_csv.py", "language": "python", "type": "data_exporter", "uuid": "export_to_csv"}, "data_exporters/pizza_data_edited.py:data_exporter:python:pizza data edited": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/pizza_sales_edited.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/pizza_data_edited.py", "language": "python", "type": "data_exporter", "uuid": "pizza_data_edited"}, "data_exporters/remarkable_scholar.py:data_exporter:python:remarkable scholar": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/ML/Sales_test_data.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/remarkable_scholar.py", "language": "python", "type": "data_exporter", "uuid": "remarkable_scholar"}, "data_exporters/review_filter_exporter.py:data_exporter:python:review filter exporter": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './review.csv'\n    FileIO().export(df, filepath)\n    \n", "file_path": "data_exporters/review_filter_exporter.py", "language": "python", "type": "data_exporter", "uuid": "review_filter_exporter"}, "data_exporters/to_csv.py:data_exporter:python:to csv": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './pizza_sales_edited.csv'\n    FileIO().export(df, filepath)\n", "file_path": "data_exporters/to_csv.py", "language": "python", "type": "data_exporter", "uuid": "to_csv"}, "data_exporters/train.py:data_exporter:python:train": {"content": "\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data(df, *args, **kwargs):\n    \"\"\"\n    Exports data to some source.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Output (optional):\n        Optionally return any object and it'll be logged and\n        displayed when inspecting the block run.\n    \"\"\"\n    # Specify your data exporting logic here\n\n\n", "file_path": "data_exporters/train.py", "language": "python", "type": "data_exporter", "uuid": "train"}, "data_exporters/train_model.py:data_exporter:python:train model": {"content": "from pandas import DataFrame\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport os\nimport pickle\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\nLABEL_COLUMN = 'Survived'\n\n\ndef build_training_and_test_set(df: DataFrame) -> None:\n    X = df.drop(columns=[LABEL_COLUMN])\n    y = df[LABEL_COLUMN]\n\n    return train_test_split(X, y)\n\n\ndef train_model(X, y) -> None:\n    model = LogisticRegression()\n    model.fit(X, y)\n\n    return model\n\n\ndef score_model(model, X, y) -> None:\n    y_pred = model.predict(X)\n\n    return accuracy_score(y, y_pred)\n\n\n@data_exporter\ndef export_data(df: DataFrame) -> None:\n    X_train, X_test, y_train, y_test = build_training_and_test_set(df)\n    model = train_model(X_train, y_train)\n\n    score = score_model(model, X_test, y_test)\n    print(f'Accuracy: {score}')\n\n    cwd = os.getcwd()\n    filename = f'{cwd}/finalized_model.lib'\n    print(f'Saving model to {filename}')\n    pickle.dump(model, open(filename, 'wb'))\n\n    print(f'Saving training and test set')\n    X_train.to_csv(f'{cwd}/X_train')\n    X_test.to_csv(f'{cwd}/X_test')\n    y_train.to_csv(f'{cwd}/y_train')\n    y_test.to_csv(f'{cwd}/y_test')\n", "file_path": "data_exporters/train_model.py", "language": "python", "type": "data_exporter", "uuid": "train_model"}, "data_loaders/category_loader.py:data_loader:python:category loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/ML/Sales_Product_Sub_Cat.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/category_loader.py", "language": "python", "type": "data_loader", "uuid": "category_loader"}, "data_loaders/channel_loader.py:data_loader:python:channel loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath2 = './mage_data/demo1/ML/Sales_Channel.csv'\n\n    return FileIO().load(filepath2)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/channel_loader.py", "language": "python", "type": "data_loader", "uuid": "channel_loader"}, "data_loaders/data_load.py:data_loader:python:data load": {"content": "if 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data(*args, **kwargs):\n    \"\"\"\n    Template code for loading data from any source.\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your data loading logic here\n\n    return {}\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/data_load.py", "language": "python", "type": "data_loader", "uuid": "data_load"}, "data_loaders/data_loader.py:data_loader:python:data loader": {"content": "import io\nimport pandas as pd\nimport requests\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(*args, **kwargs):\n    \"\"\"\n    Template for loading data from API\n    \"\"\"\n    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n    response = requests.get(url)\n\n    return pd.read_csv(io.StringIO(response.text), sep=',')\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/data_loader.py", "language": "python", "type": "data_loader", "uuid": "data_loader"}, "data_loaders/global_superstore_loader.py:data_loader:python:global superstore loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/global_superstore.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/global_superstore_loader.py", "language": "python", "type": "data_loader", "uuid": "global_superstore_loader"}, "data_loaders/load_animatedmovie.py:data_loader:python:load animatedmovie": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/TopAnimatedImDb.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_animatedmovie.py", "language": "python", "type": "data_loader", "uuid": "load_animatedmovie"}, "data_loaders/load_data_missing_hdl.py:data_loader:python:load data missing hdl": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/ML/sales_data_test_ML.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_data_missing_hdl.py", "language": "python", "type": "data_loader", "uuid": "load_data_missing_hdl"}, "data_loaders/load_titanic.py:data_loader:python:load titanic": {"content": "import io\nimport pandas as pd\nimport requests\nfrom pandas import DataFrame\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(**kwargs) -> DataFrame:\n    \"\"\"\n    Template for loading data from API\n    \"\"\"\n    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv?raw=True'\n\n    return pd.read_csv(url)\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "data_loaders/load_titanic.py", "language": "python", "type": "data_loader", "uuid": "load_titanic"}, "data_loaders/prizza_data_loader.py:data_loader:python:prizza data loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/pizza_sales3.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/prizza_data_loader.py", "language": "python", "type": "data_loader", "uuid": "prizza_data_loader"}, "data_loaders/product.py:data_loader:python:product": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/product.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/product.py", "language": "python", "type": "data_loader", "uuid": "product"}, "data_loaders/product_data_loader.py:data_loader:python:product data loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath1 = './mage_data/demo1/ML/Sales_Product.csv'\n\n    return FileIO().load(filepath1)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/product_data_loader.py", "language": "python", "type": "data_loader", "uuid": "product_data_loader"}, "data_loaders/product_loader.py:data_loader:python:product loader": {"content": "import io\nimport pandas as pd\nimport requests\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(*args, **kwargs):\n    \"\"\"\n    Template for loading data from API\n    \"\"\"\n    url = 'https://raw.githubusercontent.com/mage-ai/mage-ai/master/mage_ai/sample_datasets/product_purchases.csv'\n    response = requests.get(url)\n\n    return pd.read_csv(io.StringIO(response.text), sep=',')\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/product_loader.py", "language": "python", "type": "data_loader", "uuid": "product_loader"}, "data_loaders/sales_data_loader.py:data_loader:python:sales data loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './mage_data/demo1/ML/Sales_Data.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "data_loaders/sales_data_loader.py", "language": "python", "type": "data_loader", "uuid": "sales_data_loader"}, "scratchpads/dark_glitter.py:scratchpad:python:dark glitter": {"content": "\"\"\"\nNOTE: Scratchpad blocks are used only for experimentation and testing out code.\nThe code written here will not be executed as part of the pipeline.\n\"\"\"\npip install xgboost", "file_path": "scratchpads/dark_glitter.py", "language": "python", "type": "scratchpad", "uuid": "dark_glitter"}, "scratchpads/hopeful_aspen.py:scratchpad:python:hopeful aspen": {"content": "import matplotlib.pyplot as plt\nimport numpy as np\n\n\nt = np.arange(0.0, 2.0, 0.01)\ns = 1 + np.sin(2*np.pi*t)\nplt.plot(t, s)\n\nplt.xlabel('time (s)')\nplt.ylabel('voltage (mV)')\nplt.title('About as simple as it gets, folks')\nplt.grid(True)\nplt.show()\n", "file_path": "scratchpads/hopeful_aspen.py", "language": "python", "type": "scratchpad", "uuid": "hopeful_aspen"}, "scratchpads/merge.py:scratchpad:python:merge": {"content": "\"\"\"\nNOTE: Scratchpad blocks are used only for experimentation and testing out code.\nThe code written here will not be executed as part of the pipeline.\n\"\"\"\nfrom mage_ai.data_preparation.variable_manager import get_variable\n\n\ndf1 = get_variable('sales_prediction_time_series', 'sales_data_loader', 'output_0')\ndf2 = get_variable('sales_prediction_time_series', 'channel_loader', 'output_0')\ndf3 = get_variable('sales_prediction_time_series', 'product_data_loader', 'output_0')\ndf4 = get_variable('sales_prediction_time_series', 'category_loader', 'output_0')\n\n\n    # Specify your transformation logic here\nmerged_df = pd.merge(df1, df2, on='ChannelKey', how='left')\nmerged_df = pd.merge(merged_df, df3, on='ProductKey', how='left')\nmerged_df = pd.merge(merged_df, df4, on='ProductSubCategoryKey', how='left')\n\n", "file_path": "scratchpads/merge.py", "language": "python", "type": "scratchpad", "uuid": "merge"}, "transformers/accuracy.py:transformer:python:accuracy": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(data, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/accuracy.py", "language": "python", "type": "transformer", "uuid": "accuracy"}, "transformers/aggrigating_over_pizzacategory.py:transformer:python:aggrigating over pizzacategory": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.SUM\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#aggregation-actions\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.SUM,\n        action_code='pizza_category != null',  # Enter filtering condition on rows before aggregation\n        arguments=[\"total_price\"],  # Enter the columns to compute aggregate over\n        axis=Axis.COLUMN,\n        options={'groupby_columns': [\"pizza_category\"]},  # Enter columns to group by\n        outputs=[\n            # The number of outputs below must match the number of arguments\n            {'uuid': 'sum_total_per_category', 'column_type': 'number_with_decimals'},\n        ],\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/aggrigating_over_pizzacategory.py", "language": "python", "type": "transformer", "uuid": "aggrigating_over_pizzacategory"}, "transformers/arima_mode.py:transformer:python:arima mode": {"content": "\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(data, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n\n    from statsmodels.tsa.statespace.sarimax import SARIMAX\n\n\n\nnew_df['DateTime'] = pd.to_datetime(new_df['DateTime'])\nnew_df.set_index('DateTime', inplace=True)\n\n# Plot your data to visualize the time series\nnew_df['TotalSales'].plot(figsize=(12, 6))\nplt.title('Total Sales Over Time')\nplt.xlabel('Date')\nplt.ylabel('Total Sales')\nplt.show()\n\n# Split the data into training and testing sets\ntrain_size = int(len(new_df) * 0.8)\ntrain, test = new_df[0:train_size], new_df[train_size:]\n\n# Fit SARIMA model\norder = (1, 1, 1)  \nseasonal_order = (1, 1, 1, 12)  \n\nmodel = SARIMAX(train['TotalSales'], order=order, seasonal_order=seasonal_order)\nfit_model = model.fit(disp=False)\n\n# Forecast\nforecast_steps = len(test)\nforecast = fit_model.get_forecast(steps=forecast_steps)\n\n# Get confidence intervals\nci = forecast.conf_int()\n\n# Plot the actual vs predicted values\nplt.figure(figsize=(12, 6))\nplt.plot(train.index, train['TotalSales'], label='Train')\nplt.plot(test.index, test['TotalSales'], label='Test')\nplt.plot(forecast.index, forecast.predicted_mean, label='Forecast', color='red')\nplt.fill_between(ci.index, ci.iloc[:, 0], ci.iloc[:, 1], color='red', alpha=0.2)\nplt.title('Total Sales Forecast')\nplt.xlabel('Date')\nplt.ylabel('Total Sales')\nplt.legend()\nplt.show()\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/arima_mode.py", "language": "python", "type": "transformer", "uuid": "arima_mode"}, "transformers/check_month_wisedata.py:transformer:python:check month wisedata": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Assuming 'order_date' is in datetime format\n    # Filter the DataFrame for January 2014\n    jan_2014_data = df[(df['order_date'].dt.year == 2012) & (df['order_date'].dt.month == 1)]\n\n    # Group by 'order_date' (day) and sum the 'sales' for each day\n    daily_sales_jan_2014 = jan_2014_data.groupby(jan_2014_data['order_date'].dt.day)['sales'].sum()\n\n#    Display the total sales for each day in January 2014\n    print(\"Total Sales for Each Day in January 2014:\")\n    print(daily_sales_jan_2014)\n\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/check_month_wisedata.py", "language": "python", "type": "transformer", "uuid": "check_month_wisedata"}, "transformers/cleancolumnnames.py:transformer:python:cleancolumnnames": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.CLEAN_COLUMN_NAME\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#clean-column-names\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.CLEAN_COLUMN_NAME,\n        arguments=df.columns,\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/cleancolumnnames.py", "language": "python", "type": "transformer", "uuid": "cleancolumnnames"}, "transformers/cor.py:transformer:python:cor": {"content": "import pandas as pd  # Import pandas for data manipulation\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Calculate correlation matrix\n    correlation_matrix = df.corr()\n    print(correlation_matrix)\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/cor.py", "language": "python", "type": "transformer", "uuid": "cor"}, "transformers/corelation_.py:transformer:python:corelation ": {"content": "import pandas as pd  # Import pandas for data manipulation\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df: DataFrame, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Calculate correlation matrix\n    correlation_matrix = df.corr()\n    print(correlation_matrix)\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/corelation_.py", "language": "python", "type": "transformer", "uuid": "corelation_"}, "transformers/correlation.py:transformer:python:correlation": {"content": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df: DataFrame, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Exclude non-numeric columns before calculating correlation\n    numeric_columns = df.select_dtypes(include=[np.number])\n\n# Explore correlations between numerical features\n    correlation_matrix = numeric_columns.corr()\n\n# Plot the heatmap\n    plt.figure(figsize=(12, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n    plt.show()\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/correlation.py", "language": "python", "type": "transformer", "uuid": "correlation"}, "transformers/create_features.py:transformer:python:create features": {"content": "\nimport pandas as pd  # Import pandas for data manipulation\nimport numpy as np\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n\n    # Extract hour, day of the week, quarter, month, day of the year, day of the month,\n    # and week of the year from the 'order_date' column and add as new features.\n    # df['hour'] = df['order_date'].dt.hour\n    df['year'] = df['order_date'].dt.year\n    df['month'] = df['order_date'].dt.month\n    df['quarter'] = df['order_date'].dt.quarter\n    df['dayofweek'] = df['order_date'].dt.dayofweek\n    df['dayofyear'] = df['order_date'].dt.dayofyear\n    df['dayofmonth'] = df['order_date'].dt.day\n    df['weekofyear'] = df['order_date'].dt.isocalendar().week\n    \n    # Return the DataFrame with added features.\n    return df\n\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n\n", "file_path": "transformers/create_features.py", "language": "python", "type": "transformer", "uuid": "create_features"}, "transformers/dif.py:transformer:python:dif": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DIFF\n\n    Calculates difference from previous row along column.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#difference\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DIFF,\n        arguments=[\"total_price\"],  # Specify at most one column to compute difference with\n        axis=Axis.COLUMN,\n        outputs=[{'uuid': 'diff_total_price', 'column_type': 'number_with_decimals'}],\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/dif.py", "language": "python", "type": "transformer", "uuid": "dif"}, "transformers/difcol.py:transformer:python:difcol": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DIFF\n\n    Calculates difference from previous row along column.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#difference\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DIFF,\n        arguments=[\"unit_price\"],  # Specify at most one column to compute difference with\n        axis=Axis.COLUMN,\n        outputs=[{'uuid': 'diff_unit_price', 'column_type': 'number_with_decimals'}],\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/difcol.py", "language": "python", "type": "transformer", "uuid": "difcol"}, "transformers/difference.py:transformer:python:difference": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DIFF\n\n    Calculates difference from previous row along column.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#difference\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DIFF,\n        arguments=[],  # Specify at most one column to compute difference with\n        axis=Axis.COLUMN,\n        outputs=[{'uuid': 'new_diff_column', 'column_type': 'number_with_decimals'}],\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/difference.py", "language": "python", "type": "transformer", "uuid": "difference"}, "transformers/distribution.py:transformer:python:distribution": {"content": "import matplotlib.pyplot as plt\nimport pandas as pd\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n@transformer\ndef transform(df, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Group by 'order_date' and calculate sum of sales for each day\n    daily_sales = df.groupby('order_date')['sales'].sum()\n    channel_sales = df.groupby('channel_name')['sales'].sum()\n    brand_sales = df.groupby('brand_name')['sales'].sum()\n    category_sales = df.groupby('product_category')['sales'].sum()\n\n# Plot line plot for time series data\n    plt.figure(figsize=(12, 4))\n    plt.plot(daily_sales.index, daily_sales.values)\n    plt.xlabel('Order Date')\n    plt.ylabel('Sales')\n    plt.title('Sales Over Time')\n    plt.show()\n\n    plt.figure(figsize=(12, 4))\n    plt.plot(channel_sales.index, channel_sales.values)\n    plt.xlabel('Channel Name')\n    plt.ylabel('Sales')\n    plt.title('Sales Over Channel')\n    plt.show()\n\n    plt.figure(figsize=(12, 4))\n    plt.plot(brand_sales.index, brand_sales.values)\n    plt.xlabel('Brand Name')\n    plt.ylabel('Sales')\n    plt.title('Sales Over Brand')\n    plt.xticks(rotation=90)\n    plt.show()\n\n    plt.figure(figsize=(12, 4))\n    plt.plot(category_sales.index, category_sales.values)\n    plt.xlabel('Category Name')\n    plt.ylabel('Sales')\n    plt.title('Sales Over Category')\n    plt.show()\n\n    return df\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/distribution.py", "language": "python", "type": "transformer", "uuid": "distribution"}, "transformers/distribution2.py:transformer:python:distribution2": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(data, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/distribution2.py", "language": "python", "type": "transformer", "uuid": "distribution2"}, "transformers/drop_duplicates.py:transformer:python:drop duplicates": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DROP_DUPLICATE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#drop-duplicates\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DROP_DUPLICATE,\n        arguments=df.columns,  # Specify column names to use when comparing duplicates\n        axis=Axis.ROW,\n        options={'keep': 'first'},  # Specify whether to keep 'first' or 'last' duplicate\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/drop_duplicates.py", "language": "python", "type": "transformer", "uuid": "drop_duplicates"}, "transformers/duplicate_drop.py:transformer:python:duplicate drop": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DROP_DUPLICATE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#drop-duplicates\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DROP_DUPLICATE,\n        arguments=df.columns,  # Specify column names to use when comparing duplicates\n        axis=Axis.ROW,\n        options={'keep': 'first'},  # Specify whether to keep 'first' or 'last' duplicate\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/duplicate_drop.py", "language": "python", "type": "transformer", "uuid": "duplicate_drop"}, "transformers/duplicate_handling.py:transformer:python:duplicate handling": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DROP_DUPLICATE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#drop-duplicates\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DROP_DUPLICATE,\n        arguments=df.columns,  # Specify column names to use when comparing duplicates\n        axis=Axis.ROW,\n        options={'keep': 'first'},  # Specify whether to keep 'first' or 'last' duplicate\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/duplicate_handling.py", "language": "python", "type": "transformer", "uuid": "duplicate_handling"}, "transformers/duplicate_sales.py:transformer:python:duplicate sales": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DROP_DUPLICATE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#drop-duplicates\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DROP_DUPLICATE,\n        arguments=df.columns,  # Specify column names to use when comparing duplicates\n        axis=Axis.ROW,\n        options={'keep': 'first'},  # Specify whether to keep 'first' or 'last' duplicate\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/duplicate_sales.py", "language": "python", "type": "transformer", "uuid": "duplicate_sales"}, "transformers/extract_and_impute_numbers.py:transformer:python:extract and impute numbers": {"content": "from pandas import DataFrame\nimport math\n\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\n\n\ndef select_number_columns(df: DataFrame) -> DataFrame:\n    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n\n\ndef fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n    for col in df.columns:\n        values = sorted(df[col].dropna().tolist())\n        median_age = values[math.floor(len(values) / 2)]\n        df[[col]] = df[[col]].fillna(median_age)\n    return df\n\n\n@transformer\ndef transform_df(df: DataFrame, *args) -> DataFrame:\n    return fill_missing_values_with_median(select_number_columns(df))\n", "file_path": "transformers/extract_and_impute_numbers.py", "language": "python", "type": "transformer", "uuid": "extract_and_impute_numbers"}, "transformers/fill_in_missing_values.py:transformer:python:fill in missing values": {"content": "from pandas import DataFrame\nimport math\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\ndef select_number_columns(df: DataFrame) -> DataFrame:\n    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n\n\ndef fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n    for col in df.columns:\n        values = sorted(df[col].dropna().tolist())\n        median_age = values[math.floor(len(values) / 2)]\n        df[[col]] = df[[col]].fillna(median_age)\n    return df\n\n\n@transformer\ndef transform_df(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        df (DataFrame): Data frame from parent block.\n\n    Returns:\n        DataFrame: Transformed data frame\n    \"\"\"\n    # Specify your transformation logic here\n\n    return fill_missing_values_with_median(select_number_columns(df))\n\n\n@test\ndef test_output(df) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert df is not None, 'The output is undefined'\n", "file_path": "transformers/fill_in_missing_values.py", "language": "python", "type": "transformer", "uuid": "fill_in_missing_values"}, "transformers/filteryear.py:transformer:python:filteryear": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.FILTER\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#filter\n    \"\"\"\n\n    # Remove commas from the column 'Year'\n    df['Year'] = df['Year'].str.replace(',', '')\n\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.FILTER,\n        axis=Axis.ROW,\n        action_code='Year > 1990',  # Specify your filtering code here\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/filteryear.py", "language": "python", "type": "transformer", "uuid": "filteryear"}, "transformers/filter_1990_above.py:transformer:python:filter 1990 above": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.FILTER\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#filter\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.FILTER,\n        axis=Axis.ROW,\n        action_code='Year > 1991',  # Specify your filtering code here\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/filter_1990_above.py", "language": "python", "type": "transformer", "uuid": "filter_1990_above"}, "transformers/fixsyntaxerrors.py:transformer:python:fixsyntaxerrors": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.FIX_SYNTAX_ERRORS\n\n    This marks any improperly formatted values in each column specified\n    as invalid.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#fix-syntax-errors\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.FIX_SYNTAX_ERRORS,\n        arguments=df.columns,  # Specify columns to fix syntax errors for.\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/fixsyntaxerrors.py", "language": "python", "type": "transformer", "uuid": "fixsyntaxerrors"}, "transformers/format_category_to_capital.py:transformer:python:format category to capital": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REFORMAT\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#reformat-values\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REFORMAT,\n        arguments=[\"pizza_category\"],  # Specify columns to reformat\n        axis=Axis.COLUMN,\n        options={'reformat': 'caps_standardization', 'capitalization': 'uppercase'},  # Specify reformat action,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/format_category_to_capital.py", "language": "python", "type": "transformer", "uuid": "format_category_to_capital"}, "transformers/handling_missing_values.py:transformer:python:handling missing values": {"content": "from mage_ai.data_cleaner.transformer_actions.constants import ImputationStrategy\nfrom mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.IMPUTE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#fill-in-missing-values\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.IMPUTE,\n        arguments=df.columns,  # Specify columns to impute\n        axis=Axis.COLUMN,\n        options={'strategy': ImputationStrategy.CONSTANT},  # Specify imputation strategy\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/handling_missing_values.py", "language": "python", "type": "transformer", "uuid": "handling_missing_values"}, "transformers/labelencoder.py:transformer:python:labelencoder": {"content": "import pandas as pd\n# Specify your transformation logic here\nfrom sklearn.preprocessing import LabelEncoder\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    \n\n# Define a label encoder for each categorical variable\n    brand_encoder = LabelEncoder()\n    category_encoder = LabelEncoder()\n    channel_encoder = LabelEncoder()\n\n    # Fit and transform each categorical variable\n    df['BrandNameEn'] = brand_encoder.fit_transform(df['brand_name'])\n    df['CategoryNameEn'] = category_encoder.fit_transform(df['product_category'])\n    df['ChannelNameEn'] = channel_encoder.fit_transform(df['channel_name'])\n\n    # Print the mapping of original categories to encoded values\n    print(\"Brand Name Encoding Mapping:\")\n    print(dict(zip(brand_encoder.classes_, brand_encoder.transform(brand_encoder.classes_))))\n    print(\"\\nCategory Name Encoding Mapping:\")\n    print(dict(zip(category_encoder.classes_, category_encoder.transform(category_encoder.classes_))))\n    print(\"\\nChannel Name Encoding Mapping:\")\n    print(dict(zip(channel_encoder.classes_, channel_encoder.transform(channel_encoder.classes_))))\n\n    # Drop the original categorical columns if needed\n    df.drop(['brand_name', 'product_category', 'channel_name'], axis=1, inplace=True)\n\n\n\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/labelencoder.py", "language": "python", "type": "transformer", "uuid": "labelencoder"}, "transformers/merge_data.py:transformer:python:merge data": {"content": "\nimport pandas as pd\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform( data, data_2, data_3, data_4, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # df1 = get_variable('sales_prediction_time_series', 'sales_data_loader', 'output_0')\n    # df2 = get_variable('sales_prediction_time_series', 'channel_loader', 'output_0')\n    # df3 = get_variable('sales_prediction_time_series', 'product_data_loader', 'output_0')\n    # df4 = get_variable('sales_prediction_time_series', 'category_loader', 'output_0')\n\n\n    df1 = pd.DataFrame(data)\n    df2 = pd.DataFrame(data_2)\n    df3 = pd.DataFrame(data_3)\n    df4 = pd.DataFrame(data_4)\n\n    # Specify your transformation logic here\n    df = pd.merge(df1, df2, on='ChannelKey', how='left')\n    df = pd.merge(df, df3, on='ProductKey', how='left')\n    df = pd.merge(df, df4, on='ProductSubCategoryKey', how='left')\n\n\n\n\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/merge_data.py", "language": "python", "type": "transformer", "uuid": "merge_data"}, "transformers/model_dev.py:transformer:python:model dev": {"content": "import pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(data, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Specify the date for splitting (e.g., '2014-06-01' as the cutoff date)\n    split_date = '2014-06-01'\n\n    # Split the data into training and testing sets\n    train = data[data['order_date'] < split_date]\n    test = data[data['order_date'] >= split_date]\n\n    # Display the shapes of the training and testing sets\n    print(\"Training set shape:\", train.shape)\n    print(\"Testing set shape:\", test.shape)\n\n\n    # Define the features and target variable for training and testing datasets.\n    FEATURES = ['year', 'month', 'quarter', 'dayofweek', 'dayofyear', 'dayofmonth', 'weekofyear']\n    TARGET = 'sales'\n\n    # Extract features (X) and target variable (y) for training dataset.\n    X_train = train[FEATURES]\n    y_train = train[TARGET]\n\n    # Create an XGBoost regressor with specified hyperparameters.\n    reg = xgb.XGBRegressor(\n        base_score=0.5,\n        booster='gbtree',\n        n_estimators=10000,\n        early_stopping_rounds=50,\n        objective='reg:linear',\n        max_depth=3,\n        learning_rate=0.01\n    )\n\n    # Fit the XGBoost regressor to the training data and validate on the test set.\n    reg.fit(\n        X_train, y_train,\n        eval_set=[(X_train, y_train)],\n        verbose=100\n    )\n    # Predict the sales on the training and testing datasets\n    y_train_pred = reg.predict(X_train)\n\n\n\n    # Calculate evaluation metrics for training set\n    mae_train = mean_absolute_error(y_train, y_train_pred)\n    mse_train = mean_squared_error(y_train, y_train_pred)\n    rmse_train = mse_train ** 0.5\n    r2_train = r2_score(y_train, y_train_pred)\n\n    # Print the evaluation metrics\n    print(\"Training Set Metrics:\")\n    print(\"MAE:\", mae_train)\n    print(\"MSE:\", mse_train)\n    print(\"RMSE:\", rmse_train)\n    print(\"R-squared:\", r2_train)\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/model_dev.py", "language": "python", "type": "transformer", "uuid": "model_dev"}, "transformers/model_development.py:transformer:python:model development": {"content": "import matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport xgboost as xgb\nimport pickle\n\n\n\nimport pandas as pd  # Import pandas for data manipulation\nimport numpy as np\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n@transformer\ndef transform(data, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Specify the date for splitting (e.g., '2014-06-01' as the cutoff date)\n    split_date = '2014-06-01'\n\n    # Split the data into training and testing sets\n    train = data[data['order_date'] < split_date]\n    test = data[data['order_date'] >= split_date]\n\n    # Display the shapes of the training and testing sets\n    print(\"Training set shape:\", train.shape)\n    print(\"Testing set shape:\", test.shape)\n\n    FEATURES = ['year', 'month', 'quarter', 'dayofweek', 'dayofyear', 'dayofmonth', 'weekofyear','order_qty','price','CategoryNameEn','BrandNameEn','ChannelNameEn']\n    TARGET = 'sales'\n\n    # Extract features (X) and target variable (y) for training dataset.\n    X_train = train[FEATURES]\n    y_train = train[TARGET]\n\n    # Extract features (X) and target variable (y) for testing dataset.\n    X_test = test[FEATURES]\n    y_test = test[TARGET]\n\n    # Create an XGBoost regressor with specified hyperparameters.\n    reg = xgb.XGBRegressor(\n        base_score=0.5,\n        booster='gbtree',\n        n_estimators=10000,\n        early_stopping_rounds=50,\n        objective='reg:linear',\n        max_depth=3,\n        learning_rate=0.01\n    )\n\n    # Fit the XGBoost regressor to the training data and validate on the test set.\n    reg.fit(\n    X_train, y_train,\n    eval_set=[(X_train, y_train), (X_test, y_test)],\n    verbose=100\n    )\n\n    \n\n    # Predict the sales on the training and testing datasets\n    y_train_pred = reg.predict(X_train)\n    y_test_pred = reg.predict(X_test)\n\n\n    # Calculate evaluation metrics for training set\n    mae_train = mean_absolute_error(y_train, y_train_pred)\n    mse_train = mean_squared_error(y_train, y_train_pred)\n    rmse_train = mse_train ** 0.5\n    r2_train = r2_score(y_train, y_train_pred)\n\n    # Print the evaluation metrics\n    print(\"Training Set Metrics:\")\n    print(\"MAE:\", mae_train)\n    print(\"MSE:\", mse_train)\n    print(\"RMSE:\", rmse_train)\n    print(\"R-squared:\", r2_train)\n\n    test['prediction'] = reg.predict(X_test)\n    df = data.merge(test[['prediction']], how='left', left_index=True, right_index=True)\n\n    # Assuming SalesDate is a datetime column, convert it to the index\n    df.set_index('order_date', inplace=True)\n\n    # Plot the TotalSales column\n    ax = df[['sales']].plot(figsize=(15, 5))\n\n    # Plot the predictions using the 'prediction' column\n    df['prediction'].plot(ax=ax, style='.')\n\n    # Add legend and title\n    plt.legend(['Truth Data', 'Predictions'])\n    ax.set_title('Raw Data and Prediction')\n\n    # Show the plot\n    plt.show()\n\n    with open('xgboost_model_sales.pkl', 'wb') as f:\n        pickle.dump(reg, f)\n\n    return test\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/model_development.py", "language": "python", "type": "transformer", "uuid": "model_development"}, "transformers/naming.py:transformer:python:naming": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.CLEAN_COLUMN_NAME\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#clean-column-names\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.CLEAN_COLUMN_NAME,\n        arguments=df.columns,\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/naming.py", "language": "python", "type": "transformer", "uuid": "naming"}, "transformers/noble_voice.py:transformer:python:noble voice": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DROP_DUPLICATE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#drop-duplicates\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DROP_DUPLICATE,\n        arguments=df.columns,  # Specify column names to use when comparing duplicates\n        axis=Axis.ROW,\n        options={'keep': 'first'},  # Specify whether to keep 'first' or 'last' duplicate\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/noble_voice.py", "language": "python", "type": "transformer", "uuid": "noble_voice"}, "transformers/normalize_data.py:transformer:python:normalize data": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.NORMALIZE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#normalize-data\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.NORMALIZE,\n        arguments=[],  # Specify columns to normalize\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/normalize_data.py", "language": "python", "type": "transformer", "uuid": "normalize_data"}, "transformers/null_check.py:transformer:python:null check": {"content": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(df, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/null_check.py", "language": "python", "type": "transformer", "uuid": "null_check"}, "transformers/oitlierhandling.py:transformer:python:oitlierhandling": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE_OUTLIERS\n\n    Warning: This method uses relative outlier checks, and so repeated executions of this\n    transformer action will continue to remove data.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-outliers\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE_OUTLIERS,\n        arguments=df.columns,  # Specify columns to remove outliers from\n        axis=Axis.COLUMN,\n        options={'method': 'auto'},  # Specify algorithm to use for outlier removal\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/oitlierhandling.py", "language": "python", "type": "transformer", "uuid": "oitlierhandling"}, "transformers/outlier_handling.py:transformer:python:outlier handling": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE_OUTLIERS\n\n    Warning: This method uses relative outlier checks, and so repeated executions of this\n    transformer action will continue to remove data.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-outliers\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE_OUTLIERS,\n        arguments=df.columns,  # Specify columns to remove outliers from\n        axis=Axis.COLUMN,\n        options={'method': 'auto'},  # Specify algorithm to use for outlier removal\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/outlier_handling.py", "language": "python", "type": "transformer", "uuid": "outlier_handling"}, "transformers/product_deduplicate_transformer.py:transformer:python:product deduplicate transformer": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DROP_DUPLICATE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#drop-duplicates\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DROP_DUPLICATE,\n        arguments=df.columns,  # Specify column names to use when comparing duplicates\n        axis=Axis.ROW,\n        options={'keep': 'first'},  # Specify whether to keep 'first' or 'last' duplicate\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/product_deduplicate_transformer.py", "language": "python", "type": "transformer", "uuid": "product_deduplicate_transformer"}, "transformers/product_filter_transform.py:transformer:python:product filter transform": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.FILTER\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#filter\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.FILTER,\n        axis=Axis.ROW,\n        action_code='reviews > 50',  # Specify your filtering code here\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/product_filter_transform.py", "language": "python", "type": "transformer", "uuid": "product_filter_transform"}, "transformers/remove_descriptionrow.py:transformer:python:remove descriptionrow": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-rows\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE,\n        axis=Axis.ROW,\n        options={'rows': [\"Description\"]},  # Specify indices of rows to remove\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/remove_descriptionrow.py", "language": "python", "type": "transformer", "uuid": "remove_descriptionrow"}, "transformers/remove_dif.py:transformer:python:remove dif": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-columns\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE,\n        arguments=[\"diff_unit_price\"],  # Specify columns to remove\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/remove_dif.py", "language": "python", "type": "transformer", "uuid": "remove_dif"}, "transformers/remove_last50rows.py:transformer:python:remove last50rows": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-rows\n    \"\"\"\n\n    # Calculate the number of rows in the DataFrame\n    num_rows = len(df)\n    \n    # Specify the range of rows to remove\n    rows_to_remove = list(range(num_rows - 50, num_rows))\n\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE,\n        axis=Axis.ROW,\n        options={'rows': rows_to_remove},  # Specify indices of rows to remove\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/remove_last50rows.py", "language": "python", "type": "transformer", "uuid": "remove_last50rows"}, "transformers/remove_ordertime_column.py:transformer:python:remove ordertime column": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-columns\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE,\n        arguments=[\"order_time\"],  # Specify columns to remove\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/remove_ordertime_column.py", "language": "python", "type": "transformer", "uuid": "remove_ordertime_column"}, "transformers/remove_outliers.py:transformer:python:remove outliers": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE_OUTLIERS\n\n    Warning: This method uses relative outlier checks, and so repeated executions of this\n    transformer action will continue to remove data.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-outliers\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE_OUTLIERS,\n        arguments=df.columns,  # Specify columns to remove outliers from\n        axis=Axis.COLUMN,\n        options={'method': 'auto'},  # Specify algorithm to use for outlier removal\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/remove_outliers.py", "language": "python", "type": "transformer", "uuid": "remove_outliers"}, "transformers/remove__cols.py:transformer:python:remove  cols": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.REMOVE\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#remove-columns\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.REMOVE,\n        arguments=['ChannelKey','PromotionKey','ProductKey','ProductSubCategoryKey','StateID','Product Sub Category','ProductName', 'Manufacturer'],  # Specify columns to remove\n        axis=Axis.COLUMN,\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/remove__cols.py", "language": "python", "type": "transformer", "uuid": "remove__cols"}, "transformers/righteous_scholar.py:transformer:python:righteous scholar": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.DIFF\n\n    Calculates difference from previous row along column.\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#difference\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.DIFF,\n        arguments=[],  # Specify at most one column to compute difference with\n        axis=Axis.COLUMN,\n        outputs=[{'uuid': 'new_diff_column', 'column_type': 'number_with_decimals'}],\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/righteous_scholar.py", "language": "python", "type": "transformer", "uuid": "righteous_scholar"}, "transformers/sortbypizzacategory.py:transformer:python:sortbypizzacategory": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.SORT\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#sort\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.SORT,\n        arguments=[\"pizza_category\"],  # Specify columns to sort rows by\n        axis=Axis.ROW,\n        options={'ascending': True},\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/sortbypizzacategory.py", "language": "python", "type": "transformer", "uuid": "sortbypizzacategory"}, "transformers/yearfilter.py:transformer:python:yearfilter": {"content": "from mage_ai.data_cleaner.transformer_actions.base import BaseAction\nfrom mage_ai.data_cleaner.transformer_actions.constants import ActionType, Axis\nfrom mage_ai.data_cleaner.transformer_actions.utils import build_transformer_action\nfrom pandas import DataFrame\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef execute_transformer_action(df: DataFrame, *args, **kwargs) -> DataFrame:\n    \"\"\"\n    Execute Transformer Action: ActionType.FILTER\n\n    Docs: https://docs.mage.ai/guides/transformer-blocks#filter\n    \"\"\"\n    action = build_transformer_action(\n        df,\n        action_type=ActionType.FILTER,\n        axis=Axis.ROW,\n        action_code='Country == Australia',  # Specify your filtering code here\n    )\n\n    return BaseAction(action).execute(df)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "transformers/yearfilter.py", "language": "python", "type": "transformer", "uuid": "yearfilter"}, "/home/src/demo1/custom/nullhandline_ml.py:custom:python:home/src/demo1/custom/nullhandline ml": {"content": "import pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.impute import SimpleImputer\n\nif 'custom' not in globals():\n    from mage_ai.data_preparation.decorators import custom\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@custom\ndef transform_custom(data, *args, **kwargs):\n    \"\"\"\n    args: The output from any upstream parent blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n\n\n\n    # Load the previously trained XGBoost model\n    model = joblib.load('./data/xgboost_model_sales.pkl')\n\n    # Define features\n    FEATURES = ['year', 'month', 'quarter', 'dayofweek', 'dayofyear', 'dayofmonth', 'weekofyear','order_qty','price','CategoryNameEn','BrandNameEn','ChannelNameEn']\n    TARGET = 'sales'\n\n    # Check for null values in the 'sales' column\n    null_sales_indices = data[data['sales'].isnull()].index\n\n    # Fill null values in 'sales' column using the trained model\n    for index in null_sales_indices:\n        # Extract features for prediction\n        features = data.loc[index, FEATURES].values.reshape(1, -1)\n        \n        # Predict sales value\n        predicted_sales = model.predict(features)\n\n        \n        # Fill null value with predicted sales\n        data.at[index, 'sales'] = predicted_sales[0]\n\n    # Save the updated dataset\n    data.to_csv('./data/ML/sales_data_null_filled.csv', index=False, float_format='%.2f')  # Save the dataset to a new CSV file\n\n    # Print only the 'order_date' and 'sales' columns for the predicted rows with sales rounded to 2 decimal places\n    predicted_rows = data.loc[null_sales_indices, ['order_date', 'sales']].round({'sales': 2})\n    print(predicted_rows)\n\n    print(data.isnull().sum())\n    print(data.info())\n\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/custom/nullhandline_ml.py", "language": "python", "type": "custom", "uuid": "nullhandline_ml"}, "/home/src/demo1/data_loaders/sales_data_loader.py:data_loader:python:home/src/demo1/data loaders/sales data loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './data/ML/Sales_Data.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/data_loaders/sales_data_loader.py", "language": "python", "type": "data_loader", "uuid": "sales_data_loader"}, "/home/src/demo1/data_loaders/channel_loader.py:data_loader:python:home/src/demo1/data loaders/channel loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath2 = './data/ML/Sales_Channel.csv'\n\n    return FileIO().load(filepath2)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/data_loaders/channel_loader.py", "language": "python", "type": "data_loader", "uuid": "channel_loader"}, "/home/src/demo1/data_loaders/product_data_loader.py:data_loader:python:home/src/demo1/data loaders/product data loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath1 = './data/ML/Sales_Product.csv'\n\n    return FileIO().load(filepath1)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/data_loaders/product_data_loader.py", "language": "python", "type": "data_loader", "uuid": "product_data_loader"}, "/home/src/demo1/data_loaders/category_loader.py:data_loader:python:home/src/demo1/data loaders/category loader": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './data/ML/Sales_Product_Sub_Cat.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/data_loaders/category_loader.py", "language": "python", "type": "data_loader", "uuid": "category_loader"}, "/home/src/demo1/transformers/model_development.py:transformer:python:home/src/demo1/transformers/model development": {"content": "import matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport xgboost as xgb\nimport pickle\n\n\n\nimport pandas as pd  # Import pandas for data manipulation\nimport numpy as np\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n@transformer\ndef transform(data, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    # Specify your transformation logic here\n    # Specify the date for splitting (e.g., '2014-06-01' as the cutoff date)\n    split_date = '2014-06-01'\n\n    # Split the data into training and testing sets\n    train = data[data['order_date'] < split_date]\n    test = data[data['order_date'] >= split_date]\n\n    # Display the shapes of the training and testing sets\n    print(\"Training set shape:\", train.shape)\n    print(\"Testing set shape:\", test.shape)\n\n    FEATURES = ['year', 'month', 'quarter', 'dayofweek', 'dayofyear', 'dayofmonth', 'weekofyear','order_qty','price','CategoryNameEn','BrandNameEn','ChannelNameEn']\n    TARGET = 'sales'\n\n    # Extract features (X) and target variable (y) for training dataset.\n    X_train = train[FEATURES]\n    y_train = train[TARGET]\n\n    # Extract features (X) and target variable (y) for testing dataset.\n    X_test = test[FEATURES]\n    y_test = test[TARGET]\n\n    # Create an XGBoost regressor with specified hyperparameters.\n    reg = xgb.XGBRegressor(\n        base_score=0.5,\n        booster='gbtree',\n        n_estimators=10000,\n        early_stopping_rounds=50,\n        objective='reg:linear',\n        max_depth=3,\n        learning_rate=0.01\n    )\n\n    # Fit the XGBoost regressor to the training data and validate on the test set.\n    reg.fit(\n    X_train, y_train,\n    eval_set=[(X_train, y_train), (X_test, y_test)],\n    verbose=100\n    )\n\n    \n\n    # Predict the sales on the training and testing datasets\n    y_train_pred = reg.predict(X_train)\n    y_test_pred = reg.predict(X_test)\n\n\n    # Calculate evaluation metrics for training set\n    mae_train = mean_absolute_error(y_train, y_train_pred)\n    mse_train = mean_squared_error(y_train, y_train_pred)\n    rmse_train = mse_train ** 0.5\n    r2_train = r2_score(y_train, y_train_pred)\n\n    # Print the evaluation metrics\n    print(\"Training Set Metrics:\")\n    print(\"MAE:\", mae_train)\n    print(\"MSE:\", mse_train)\n    print(\"RMSE:\", rmse_train)\n    print(\"R-squared:\", r2_train)\n\n    test['prediction'] = reg.predict(X_test)\n    df = data.merge(test[['prediction']], how='left', left_index=True, right_index=True)\n\n    # Assuming SalesDate is a datetime column, convert it to the index\n    df.set_index('order_date', inplace=True)\n\n    # Plot the TotalSales column\n    ax = df[['sales']].plot(figsize=(15, 5))\n\n    # Plot the predictions using the 'prediction' column\n    df['prediction'].plot(ax=ax, style='.')\n\n    # Add legend and title\n    plt.legend(['Truth Data', 'Predictions'])\n    ax.set_title('Raw Data and Prediction')\n\n    # Show the plot\n    plt.show()\n\n    with open('./data/xgboost_model_sales.pkl', 'wb') as f:\n        pickle.dump(reg, f)\n\n    return test\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/transformers/model_development.py", "language": "python", "type": "transformer", "uuid": "model_development"}, "/home/src/demo1/data_exporters/remarkable_scholar.py:data_exporter:python:home/src/demo1/data exporters/remarkable scholar": {"content": "from mage_ai.io.file import FileIO\nfrom pandas import DataFrame\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n\n@data_exporter\ndef export_data_to_file(df: DataFrame, **kwargs) -> None:\n    \"\"\"\n    Template for exporting data to filesystem.\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './data/ML/Sales_test_data.csv'\n    FileIO().export(df, filepath)\n", "file_path": "/home/src/demo1/data_exporters/remarkable_scholar.py", "language": "python", "type": "data_exporter", "uuid": "remarkable_scholar"}, "/home/src/demo1/data_loaders/load_data_missing_hdl.py:data_loader:python:home/src/demo1/data loaders/load data missing hdl": {"content": "from mage_ai.io.file import FileIO\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_file(*args, **kwargs):\n    \"\"\"\n    Template for loading data from filesystem.\n    Load data from 1 file or multiple file directories.\n\n    For multiple directories, use the following:\n        FileIO().load(file_directories=['dir_1', 'dir_2'])\n\n    Docs: https://docs.mage.ai/design/data-loading#fileio\n    \"\"\"\n    filepath = './data/ML/sales_data_test_ML.csv'\n\n    return FileIO().load(filepath)\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/data_loaders/load_data_missing_hdl.py", "language": "python", "type": "data_loader", "uuid": "load_data_missing_hdl"}, "/home/src/demo1/transformers/merge_data.py:transformer:python:home/src/demo1/transformers/merge data": {"content": "\nimport pandas as pd\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform( data, data_2, data_3, data_4, *args, **kwargs):\n    \"\"\"\n    Template code for a transformer block.\n\n    Add more parameters to this function if this block has multiple parent blocks.\n    There should be one parameter for each output variable from each parent block.\n\n    Args:\n        data: The output from the upstream parent block\n        args: The output from any additional upstream blocks (if applicable)\n\n    Returns:\n        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n    \"\"\"\n    df1 = pd.DataFrame(data)\n    df2 = pd.DataFrame(data_2)\n    df3 = pd.DataFrame(data_3)\n    df4 = pd.DataFrame(data_4)\n\n    # Specify your transformation logic here\n    df = pd.merge(df1, df2, on='ChannelKey', how='left')\n    df = pd.merge(df, df3, on='ProductKey', how='left')\n    df = pd.merge(df, df4, on='ProductSubCategoryKey', how='left')\n\n\n\n\n\n    return df\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n", "file_path": "/home/src/demo1/transformers/merge_data.py", "language": "python", "type": "transformer", "uuid": "merge_data"}}, "custom_block_template": {}, "mage_template": {"data_loaders/deltalake/s3.py:data_loader:python:Amazon S3:Load a Delta Table from Amazon S3.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_loaders/deltalake/s3.py"}, "data_loaders/deltalake/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Load a Delta Table from Azure Blob Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/deltalake/azure_blob_storage.py"}, "data_loaders/deltalake/gcs.py:data_loader:python:Google Cloud Storage:Load a Delta Table from Google Cloud Storage.:Delta Lake": {"block_type": "data_loader", "description": "Load a Delta Table from Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/deltalake/gcs.py"}, "data_loaders/mongodb.py:data_loader:python:MongoDB:Load data from MongoDB.:Databases (NoSQL)": {"block_type": "data_loader", "description": "Load data from MongoDB.", "groups": ["Databases (NoSQL)"], "language": "python", "name": "MongoDB", "path": "data_loaders/mongodb.py"}, "data_loaders/mssql.py:data_loader:python:MSSQL:Load data from MSSQL.:Databases": {"block_type": "data_loader", "description": "Load data from MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_loaders/mssql.py"}, "data_exporters/deltalake/s3.py:data_exporter:python:Amazon S3:Export data to a Delta Table in Amazon S3.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Amazon S3.", "groups": ["Delta Lake"], "language": "python", "name": "Amazon S3", "path": "data_exporters/deltalake/s3.py"}, "data_exporters/deltalake/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Export data to a Delta Table in Azure Blob Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Azure Blob Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/deltalake/azure_blob_storage.py"}, "data_exporters/deltalake/gcs.py:data_exporter:python:Google Cloud Storage:Export data to a Delta Table in Google Cloud Storage.:Delta Lake": {"block_type": "data_exporter", "description": "Export data to a Delta Table in Google Cloud Storage.", "groups": ["Delta Lake"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/deltalake/gcs.py"}, "data_exporters/mongodb.py:data_exporter:python:MongoDB:Export data to MongoDB.": {"block_type": "data_exporter", "description": "Export data to MongoDB.", "language": "python", "name": "MongoDB", "path": "data_exporters/mongodb.py"}, "data_exporters/mssql.py:data_exporter:python:MSSQL:Export data to MSSQL.:Databases": {"block_type": "data_exporter", "description": "Export data to MSSQL.", "groups": ["Databases"], "language": "python", "name": "MSSQL", "path": "data_exporters/mssql.py"}, "data_loaders/orchestration/triggers/default.jinja:data_loader:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_loader", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_loaders/orchestration/triggers/default.jinja"}, "data_exporters/orchestration/triggers/default.jinja:data_exporter:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "data_exporter", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "data_exporters/orchestration/triggers/default.jinja"}, "callbacks/base.jinja:callback:python:Base template:Base template with empty functions.": {"block_type": "callback", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "callbacks/base.jinja"}, "callbacks/orchestration/triggers/default.jinja:callback:python:Trigger pipeline:Trigger another pipeline to run.:Orchestration": {"block_type": "callback", "description": "Trigger another pipeline to run.", "groups": ["Orchestration"], "language": "python", "name": "Trigger pipeline", "path": "callbacks/orchestration/triggers/default.jinja"}, "conditionals/base.jinja:conditional:python:Base template:Base template with empty functions.": {"block_type": "conditional", "description": "Base template with empty functions.", "language": "python", "name": "Base template", "path": "conditionals/base.jinja"}, "data_loaders/default.jinja:data_loader:python:Base template (generic)": {"block_type": "data_loader", "language": "python", "name": "Base template (generic)", "path": "data_loaders/default.jinja"}, "data_loaders/s3.py:data_loader:python:Amazon S3:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_loaders/s3.py"}, "data_loaders/azure_blob_storage.py:data_loader:python:Azure Blob Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_loaders/azure_blob_storage.py"}, "data_loaders/google_cloud_storage.py:data_loader:python:Google Cloud Storage:Data lakes": {"block_type": "data_loader", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_loaders/google_cloud_storage.py"}, "data_loaders/redshift.py:data_loader:python:Amazon Redshift:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_loaders/redshift.py"}, "data_loaders/bigquery.py:data_loader:python:Google BigQuery:Load data from Google BigQuery.:Data warehouses": {"block_type": "data_loader", "description": "Load data from Google BigQuery.", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_loaders/bigquery.py"}, "data_loaders/snowflake.py:data_loader:python:Snowflake:Data warehouses": {"block_type": "data_loader", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_loaders/snowflake.py"}, "data_loaders/algolia.py:data_loader:python:Algolia:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_loaders/algolia.py"}, "data_loaders/chroma.py:data_loader:python:Chroma:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_loaders/chroma.py"}, "data_loaders/duckdb.py:data_loader:python:DuckDB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_loaders/duckdb.py"}, "data_loaders/mysql.py:data_loader:python:MySQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_loaders/mysql.py"}, "data_loaders/oracledb.py:data_loader:python:Oracle DB:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Oracle DB", "path": "data_loaders/oracledb.py"}, "data_loaders/postgres.py:data_loader:python:PostgreSQL:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_loaders/postgres.py"}, "data_loaders/qdrant.py:data_loader:python:Qdrant:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_loaders/qdrant.py"}, "data_loaders/weaviate.py:data_loader:python:Weaviate:Databases": {"block_type": "data_loader", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_loaders/weaviate.py"}, "data_loaders/api.py:data_loader:python:API:Fetch data from an API request.": {"block_type": "data_loader", "description": "Fetch data from an API request.", "language": "python", "name": "API", "path": "data_loaders/api.py"}, "data_loaders/file.py:data_loader:python:Local file:Load data from a file on your machine.": {"block_type": "data_loader", "description": "Load data from a file on your machine.", "language": "python", "name": "Local file", "path": "data_loaders/file.py"}, "data_loaders/google_sheets.py:data_loader:python:Google Sheets:Load data from a worksheet in Google Sheets.": {"block_type": "data_loader", "description": "Load data from a worksheet in Google Sheets.", "language": "python", "name": "Google Sheets", "path": "data_loaders/google_sheets.py"}, "data_loaders/druid.py:data_loader:python:Druid": {"block_type": "data_loader", "language": "python", "name": "Druid", "path": "data_loaders/druid.py"}, "transformers/default.jinja:transformer:python:Base template (generic)": {"block_type": "transformer", "language": "python", "name": "Base template (generic)", "path": "transformers/default.jinja"}, "transformers/data_warehouse_transformer.jinja:transformer:python:Amazon Redshift:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "redshift", "data_source_handler": "Redshift"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Google BigQuery:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "", "data_source": "bigquery", "data_source_handler": "BigQuery"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:Snowflake:Data warehouses": {"block_type": "transformer", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "snowflake", "data_source_handler": "Snowflake"}}, "transformers/data_warehouse_transformer.jinja:transformer:python:PostgreSQL:Databases": {"block_type": "transformer", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "transformers/data_warehouse_transformer.jinja", "template_variables": {"additional_args": "\n        loader.commit() # Permanently apply database changes", "data_source": "postgres", "data_source_handler": "Postgres"}}, "transformers/transformer_actions/row/drop_duplicate.py:transformer:python:Drop duplicate rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Drop duplicate rows", "path": "transformers/transformer_actions/row/drop_duplicate.py"}, "transformers/transformer_actions/row/filter.py:transformer:python:Filter rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Filter rows", "path": "transformers/transformer_actions/row/filter.py"}, "transformers/transformer_actions/row/remove.py:transformer:python:Remove rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Remove rows", "path": "transformers/transformer_actions/row/remove.py"}, "transformers/transformer_actions/row/sort.py:transformer:python:Sort rows:Row actions": {"block_type": "transformer", "groups": ["Row actions"], "language": "python", "name": "Sort rows", "path": "transformers/transformer_actions/row/sort.py"}, "transformers/transformer_actions/column/average.py:transformer:python:Average value of column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Average value of column", "path": "transformers/transformer_actions/column/average.py"}, "transformers/transformer_actions/column/count_distinct.py:transformer:python:Count unique values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Count unique values in column", "path": "transformers/transformer_actions/column/count_distinct.py"}, "transformers/transformer_actions/column/first.py:transformer:python:First value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "First value in column", "path": "transformers/transformer_actions/column/first.py"}, "transformers/transformer_actions/column/last.py:transformer:python:Last value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Last value in column", "path": "transformers/transformer_actions/column/last.py"}, "transformers/transformer_actions/column/max.py:transformer:python:Maximum value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Maximum value in column", "path": "transformers/transformer_actions/column/max.py"}, "transformers/transformer_actions/column/median.py:transformer:python:Median value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Median value in column", "path": "transformers/transformer_actions/column/median.py"}, "transformers/transformer_actions/column/min.py:transformer:python:Min value in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Min value in column", "path": "transformers/transformer_actions/column/min.py"}, "transformers/transformer_actions/column/sum.py:transformer:python:Sum of all values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Sum of all values in column", "path": "transformers/transformer_actions/column/sum.py"}, "transformers/transformer_actions/column/count.py:transformer:python:Total count of values in column:Column actions:Aggregate": {"block_type": "transformer", "groups": ["Column actions", "Aggregate"], "language": "python", "name": "Total count of values in column", "path": "transformers/transformer_actions/column/count.py"}, "transformers/transformer_actions/column/clean_column_name.py:transformer:python:Clean column name:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Clean column name", "path": "transformers/transformer_actions/column/clean_column_name.py"}, "transformers/transformer_actions/column/fix_syntax_errors.py:transformer:python:Fix syntax errors:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Fix syntax errors", "path": "transformers/transformer_actions/column/fix_syntax_errors.py"}, "transformers/transformer_actions/column/reformat.py:transformer:python:Reformat values in column:Column actions:Formatting": {"block_type": "transformer", "groups": ["Column actions", "Formatting"], "language": "python", "name": "Reformat values in column", "path": "transformers/transformer_actions/column/reformat.py"}, "transformers/transformer_actions/column/select.py:transformer:python:Keep column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Keep column(s)", "path": "transformers/transformer_actions/column/select.py"}, "transformers/transformer_actions/column/remove.py:transformer:python:Remove column(s):Column actions:Column removal": {"block_type": "transformer", "groups": ["Column actions", "Column removal"], "language": "python", "name": "Remove column(s)", "path": "transformers/transformer_actions/column/remove.py"}, "transformers/transformer_actions/column/shift_down.py:transformer:python:Shift row values down:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values down", "path": "transformers/transformer_actions/column/shift_down.py"}, "transformers/transformer_actions/column/shift_up.py:transformer:python:Shift row values up:Column actions:Shift": {"block_type": "transformer", "groups": ["Column actions", "Shift"], "language": "python", "name": "Shift row values up", "path": "transformers/transformer_actions/column/shift_up.py"}, "transformers/transformer_actions/column/normalize.py:transformer:python:Normalize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Normalize data", "path": "transformers/transformer_actions/column/normalize.py"}, "transformers/transformer_actions/column/standardize.py:transformer:python:Standardize data:Column actions:Feature scaling": {"block_type": "transformer", "groups": ["Column actions", "Feature scaling"], "language": "python", "name": "Standardize data", "path": "transformers/transformer_actions/column/standardize.py"}, "transformers/transformer_actions/column/impute.py:transformer:python:Fill in missing values:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Fill in missing values", "path": "transformers/transformer_actions/column/impute.py"}, "transformers/transformer_actions/column/remove_outliers.py:transformer:python:Remove outliers:Column actions:Data cleaning": {"block_type": "transformer", "groups": ["Column actions", "Data cleaning"], "language": "python", "name": "Remove outliers", "path": "transformers/transformer_actions/column/remove_outliers.py"}, "transformers/transformer_actions/column/diff.py:transformer:python:Calculate difference between values:Column actions:Feature extraction": {"block_type": "transformer", "groups": ["Column actions", "Feature extraction"], "language": "python", "name": "Calculate difference between values", "path": "transformers/transformer_actions/column/diff.py"}, "data_exporters/default.jinja:data_exporter:python:Base template (generic)": {"block_type": "data_exporter", "language": "python", "name": "Base template (generic)", "path": "data_exporters/default.jinja"}, "data_exporters/file.py:data_exporter:python:Local file": {"block_type": "data_exporter", "language": "python", "name": "Local file", "path": "data_exporters/file.py"}, "data_exporters/google_sheets.py:data_exporter:python:Google Sheets": {"block_type": "data_exporter", "language": "python", "name": "Google Sheets", "path": "data_exporters/google_sheets.py"}, "data_exporters/s3.py:data_exporter:python:Amazon S3:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "data_exporters/s3.py"}, "data_exporters/azure_blob_storage.py:data_exporter:python:Azure Blob Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Azure Blob Storage", "path": "data_exporters/azure_blob_storage.py"}, "data_exporters/google_cloud_storage.py:data_exporter:python:Google Cloud Storage:Data lakes": {"block_type": "data_exporter", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "data_exporters/google_cloud_storage.py"}, "data_exporters/redshift.py:data_exporter:python:Amazon Redshift:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "data_exporters/redshift.py"}, "data_exporters/bigquery.py:data_exporter:python:Google BigQuery:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "data_exporters/bigquery.py"}, "data_exporters/snowflake.py:data_exporter:python:Snowflake:Data warehouses": {"block_type": "data_exporter", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "data_exporters/snowflake.py"}, "data_exporters/algolia.py:data_exporter:python:Algolia:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Algolia", "path": "data_exporters/algolia.py"}, "data_exporters/chroma.py:data_exporter:python:Chroma:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Chroma", "path": "data_exporters/chroma.py"}, "data_exporters/duckdb.py:data_exporter:python:DuckDB:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "DuckDB", "path": "data_exporters/duckdb.py"}, "data_exporters/mysql.py:data_exporter:python:MySQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "data_exporters/mysql.py"}, "data_exporters/postgres.py:data_exporter:python:PostgreSQL:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "data_exporters/postgres.py"}, "data_exporters/qdrant.py:data_exporter:python:Qdrant:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Qdrant", "path": "data_exporters/qdrant.py"}, "data_exporters/weaviate.py:data_exporter:python:Weaviate:Databases": {"block_type": "data_exporter", "groups": ["Databases"], "language": "python", "name": "Weaviate", "path": "data_exporters/weaviate.py"}, "sensors/default.py:sensor:python:Base template (generic)": {"block_type": "sensor", "language": "python", "name": "Base template (generic)", "path": "sensors/default.py"}, "sensors/s3.py:sensor:python:Amazon S3:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Amazon S3", "path": "sensors/s3.py"}, "sensors/google_cloud_storage.py:sensor:python:Google Cloud Storage:Data lakes": {"block_type": "sensor", "groups": ["Data lakes"], "language": "python", "name": "Google Cloud Storage", "path": "sensors/google_cloud_storage.py"}, "sensors/redshift.py:sensor:python:Amazon Redshift:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Amazon Redshift", "path": "sensors/redshift.py"}, "sensors/bigquery.py:sensor:python:Google BigQuery:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Google BigQuery", "path": "sensors/bigquery.py"}, "sensors/snowflake.py:sensor:python:Snowflake:Data warehouses": {"block_type": "sensor", "groups": ["Data warehouses"], "language": "python", "name": "Snowflake", "path": "sensors/snowflake.py"}, "sensors/mysql.py:sensor:python:MySQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "MySQL", "path": "sensors/mysql.py"}, "sensors/postgres.py:sensor:python:PostgreSQL:Databases": {"block_type": "sensor", "groups": ["Databases"], "language": "python", "name": "PostgreSQL", "path": "sensors/postgres.py"}}}